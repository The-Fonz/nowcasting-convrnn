{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build convrnn\n",
    "\n",
    "So we've downloaded the dataset and analyzed and visualized it. We're ready now for the next step: building the convrnn.\n",
    "\n",
    "We first test it with a synthetic dataset: a ball that bounces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!conda install scikit-image\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd.variable import Variable\n",
    "\n",
    "from convlstm_pytorch import ConvLSTM, ConvLSTMCell\n",
    "from synthetic_datasets import Ball\n",
    "import utils\n",
    "\n",
    "# Give init parameters here\n",
    "# b = Ball()\n",
    "# Calling an instance of Ball generates a batch of images\n",
    "# utils.plotting.plot_synthetic(b(sequence_length=100)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know how the lstm functions with its output range. Let's do some experiments to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range   0.0000  0.0011\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f80dca13a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b = Ball(shape=(10,10), radius=(3,3))\n",
    "l = ConvLSTMCell(input_size=(10,10), input_dim=1, hidden_dim=1, kernel_size=(1,1), bias=True, use_cuda=False)\n",
    "\n",
    "# Init weights\n",
    "# l.conv.weight.data.fill_(0)\n",
    "# l.conv.weight.data[3,0].fill_(1)\n",
    "# Bias order: (i,f,o,g) where g = C_candidate\n",
    "\n",
    "h,c = l.init_hidden(batch_size=1)\n",
    "# (b,t,c,h,w)\n",
    "inp = Variable(torch.from_numpy(b(sequence_length=1).astype(np.float32)))[0]\n",
    "# inp = Variable(torch.ones_like(torch.from_numpy(b(sequence_length=1).astype(np.float32))))[np.newaxis]\n",
    "# inp = inp * 1\n",
    "\n",
    "h_o, c_o = l(inp, (h,c))\n",
    "\n",
    "im = c_o[0].data.numpy()\n",
    "print(\"Range   {:.4f}  {:.4f}\".format(im.min(), im.max()))\n",
    "\n",
    "plt.close('all')\n",
    "utils.plotting.plot_synthetic(im);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch    0 loss: 0.50105 min  0.5009 max  0.5013\n",
      "Batch    1 loss: 0.48978 min  0.4487 max  0.5050\n",
      "Batch    2 loss: 0.44024 min  0.2986 max  0.5353\n",
      "Batch    3 loss: 0.40618 min  0.2856 max  0.5237\n",
      "Batch    4 loss: 0.39506 min  0.2790 max  0.6236\n",
      "Batch    5 loss: 0.37776 min  0.2544 max  0.4522\n",
      "Batch    6 loss: 0.36254 min  0.2340 max  0.4707\n",
      "Batch    7 loss: 0.34741 min  0.2164 max  0.4891\n",
      "Batch    8 loss: 0.33630 min  0.2013 max  0.4955\n",
      "Batch    9 loss: 0.32548 min  0.1875 max  0.4981\n",
      "Batch   10 loss: 0.31414 min  0.1751 max  0.5000\n",
      "Batch   11 loss: 0.31170 min  0.1634 max  0.5011\n",
      "Batch   12 loss: 0.30997 min  0.1524 max  0.5018\n",
      "Batch   13 loss: 0.31095 min  0.1425 max  0.5041\n",
      "Batch   14 loss: 0.29300 min  0.1336 max  0.5066\n",
      "Batch   15 loss: 0.29742 min  0.1255 max  0.5087\n",
      "Batch   16 loss: 0.29857 min  0.1178 max  0.5108\n",
      "Batch   17 loss: 0.28173 min  0.1109 max  0.5127\n",
      "Batch   18 loss: 0.28875 min  0.1046 max  0.5152\n",
      "Batch   19 loss: 0.28569 min  0.0990 max  0.5177\n",
      "Batch   20 loss: 0.29421 min  0.0938 max  0.5200\n",
      "Batch   21 loss: 0.27907 min  0.0891 max  0.5225\n",
      "Batch   22 loss: 0.27572 min  0.0849 max  0.5250\n",
      "Batch   23 loss: 0.27636 min  0.0812 max  0.5279\n",
      "Batch   24 loss: 0.27610 min  0.0779 max  0.5309\n",
      "Batch   25 loss: 0.27790 min  0.0748 max  0.5339\n",
      "Batch   26 loss: 0.27403 min  0.0721 max  0.5370\n",
      "Batch   27 loss: 0.27219 min  0.0696 max  0.5400\n",
      "Batch   28 loss: 0.27273 min  0.0674 max  0.5434\n",
      "Batch   29 loss: 0.27213 min  0.0654 max  0.5468\n",
      "Batch   30 loss: 0.26232 min  0.0635 max  0.5500\n",
      "Batch   31 loss: 0.26974 min  0.0617 max  0.5534\n",
      "Batch   32 loss: 0.26980 min  0.0601 max  0.5569\n",
      "Batch   33 loss: 0.27124 min  0.0588 max  0.5604\n",
      "Batch   34 loss: 0.26757 min  0.0575 max  0.5639\n",
      "Batch   35 loss: 0.26328 min  0.0563 max  0.5673\n",
      "Batch   36 loss: 0.25915 min  0.0552 max  0.5708\n",
      "Batch   37 loss: 0.25965 min  0.0542 max  0.5743\n",
      "Batch   38 loss: 0.26120 min  0.0531 max  0.5777\n",
      "Batch   39 loss: 0.25804 min  0.0523 max  0.5813\n",
      "Batch   40 loss: 0.25839 min  0.0514 max  0.5848\n",
      "Batch   41 loss: 0.24450 min  0.0506 max  0.5882\n",
      "Batch   42 loss: 0.24334 min  0.0498 max  0.5918\n",
      "Batch   43 loss: 0.24130 min  0.0491 max  0.5953\n",
      "Batch   44 loss: 0.23846 min  0.0484 max  0.5989\n",
      "Batch   45 loss: 0.24670 min  0.0477 max  0.6025\n",
      "Batch   46 loss: 0.24685 min  0.0470 max  0.6059\n",
      "Batch   47 loss: 0.24167 min  0.0464 max  0.6094\n",
      "Batch   48 loss: 0.23842 min  0.0457 max  0.6128\n",
      "Batch   49 loss: 0.23566 min  0.0451 max  0.6162\n",
      "Batch   50 loss: 0.23018 min  0.0445 max  0.6196\n",
      "Batch   51 loss: 0.23028 min  0.0440 max  0.6231\n",
      "Batch   52 loss: 0.23395 min  0.0434 max  0.6264\n",
      "Batch   53 loss: 0.22482 min  0.0429 max  0.6298\n",
      "Batch   54 loss: 0.23267 min  0.0424 max  0.6332\n",
      "Batch   55 loss: 0.23565 min  0.0419 max  0.6365\n",
      "Batch   56 loss: 0.23668 min  0.0416 max  0.6398\n",
      "Batch   57 loss: 0.21758 min  0.0409 max  0.6429\n",
      "Batch   58 loss: 0.22703 min  0.0403 max  0.6460\n",
      "Batch   59 loss: 0.22789 min  0.0399 max  0.6492\n",
      "Batch   60 loss: 0.21173 min  0.0394 max  0.6522\n",
      "Batch   61 loss: 0.22371 min  0.0390 max  0.6553\n",
      "Batch   62 loss: 0.22253 min  0.0385 max  0.6583\n",
      "Batch   63 loss: 0.20684 min  0.0381 max  0.6614\n",
      "Batch   64 loss: 0.21470 min  0.0376 max  0.6643\n",
      "Batch   65 loss: 0.22439 min  0.0370 max  0.6672\n",
      "Batch   66 loss: 0.21158 min  0.0366 max  0.6701\n",
      "Batch   67 loss: 0.21302 min  0.0361 max  0.6730\n",
      "Batch   68 loss: 0.22107 min  0.0356 max  0.6758\n",
      "Batch   69 loss: 0.20713 min  0.0351 max  0.6785\n",
      "Batch   70 loss: 0.21512 min  0.0347 max  0.6813\n",
      "Batch   71 loss: 0.20582 min  0.0343 max  0.6841\n",
      "Batch   72 loss: 0.20913 min  0.0337 max  0.6866\n",
      "Batch   73 loss: 0.20828 min  0.0333 max  0.6892\n",
      "Batch   74 loss: 0.20132 min  0.0328 max  0.6919\n",
      "Batch   75 loss: 0.19495 min  0.0323 max  0.6943\n",
      "Batch   76 loss: 0.19946 min  0.0318 max  0.6968\n",
      "Batch   77 loss: 0.20648 min  0.0314 max  0.6994\n",
      "Batch   78 loss: 0.20191 min  0.0309 max  0.7019\n",
      "Batch   79 loss: 0.20573 min  0.0304 max  0.7042\n",
      "Batch   80 loss: 0.19731 min  0.0301 max  0.7066\n",
      "Batch   81 loss: 0.19152 min  0.0297 max  0.7090\n",
      "Batch   82 loss: 0.20059 min  0.0292 max  0.7113\n",
      "Batch   83 loss: 0.20119 min  0.0288 max  0.7136\n",
      "Batch   84 loss: 0.19900 min  0.0285 max  0.7160\n",
      "Batch   85 loss: 0.19291 min  0.0280 max  0.7182\n",
      "Batch   86 loss: 0.19801 min  0.0276 max  0.7204\n",
      "Batch   87 loss: 0.19874 min  0.0273 max  0.7227\n",
      "Batch   88 loss: 0.19141 min  0.0269 max  0.7249\n",
      "Batch   89 loss: 0.18471 min  0.0263 max  0.7269\n",
      "Batch   90 loss: 0.18718 min  0.0259 max  0.7290\n",
      "Batch   91 loss: 0.18557 min  0.0255 max  0.7311\n",
      "Batch   92 loss: 0.18540 min  0.0250 max  0.7331\n",
      "Batch   93 loss: 0.18029 min  0.0246 max  0.7352\n",
      "Batch   94 loss: 0.18134 min  0.0243 max  0.7374\n",
      "Batch   95 loss: 0.17608 min  0.0240 max  0.7395\n",
      "Batch   96 loss: 0.18051 min  0.0235 max  0.7414\n",
      "Batch   97 loss: 0.17817 min  0.0231 max  0.7434\n",
      "Batch   98 loss: 0.17895 min  0.0228 max  0.7454\n",
      "Batch   99 loss: 0.19160 min  0.0224 max  0.7473\n",
      "Batch  100 loss: 0.18066 min  0.0220 max  0.7492\n",
      "Batch  101 loss: 0.17960 min  0.0217 max  0.7512\n",
      "Batch  102 loss: 0.17483 min  0.0213 max  0.7529\n",
      "Batch  103 loss: 0.17965 min  0.0210 max  0.7547\n",
      "Batch  104 loss: 0.17441 min  0.0206 max  0.7566\n",
      "Batch  105 loss: 0.16530 min  0.0203 max  0.7583\n",
      "Batch  106 loss: 0.16858 min  0.0200 max  0.7601\n",
      "Batch  107 loss: 0.17581 min  0.0197 max  0.7619\n",
      "Batch  108 loss: 0.16773 min  0.0194 max  0.7637\n",
      "Batch  109 loss: 0.17651 min  0.0191 max  0.7655\n",
      "Batch  110 loss: 0.16765 min  0.0189 max  0.7673\n",
      "Batch  111 loss: 0.16534 min  0.0186 max  0.7689\n",
      "Batch  112 loss: 0.16764 min  0.0183 max  0.7706\n",
      "Batch  113 loss: 0.16653 min  0.0181 max  0.7724\n",
      "Batch  114 loss: 0.15755 min  0.0179 max  0.7741\n",
      "Batch  115 loss: 0.17566 min  0.0175 max  0.7757\n",
      "Batch  116 loss: 0.16771 min  0.0174 max  0.7775\n",
      "Batch  117 loss: 0.16864 min  0.0171 max  0.7791\n",
      "Batch  118 loss: 0.17103 min  0.0168 max  0.7805\n",
      "Batch  119 loss: 0.16832 min  0.0166 max  0.7821\n",
      "Batch  120 loss: 0.16428 min  0.0164 max  0.7837\n",
      "Batch  121 loss: 0.16413 min  0.0161 max  0.7851\n",
      "Batch  122 loss: 0.16170 min  0.0159 max  0.7866\n",
      "Batch  123 loss: 0.15789 min  0.0157 max  0.7881\n",
      "Batch  124 loss: 0.15349 min  0.0155 max  0.7895\n",
      "Batch  125 loss: 0.15330 min  0.0153 max  0.7910\n",
      "Batch  126 loss: 0.15745 min  0.0151 max  0.7924\n",
      "Batch  127 loss: 0.15066 min  0.0149 max  0.7938\n",
      "Batch  128 loss: 0.16067 min  0.0147 max  0.7952\n",
      "Batch  129 loss: 0.16426 min  0.0144 max  0.7966\n",
      "Batch  130 loss: 0.16430 min  0.0143 max  0.7980\n",
      "Batch  131 loss: 0.14797 min  0.0141 max  0.7994\n",
      "Batch  132 loss: 0.15341 min  0.0139 max  0.8007\n",
      "Batch  133 loss: 0.16009 min  0.0138 max  0.8020\n",
      "Batch  134 loss: 0.15527 min  0.0136 max  0.8033\n",
      "Batch  135 loss: 0.15308 min  0.0134 max  0.8047\n",
      "Batch  136 loss: 0.15342 min  0.0133 max  0.8060\n",
      "Batch  137 loss: 0.15876 min  0.0131 max  0.8071\n",
      "Batch  138 loss: 0.15240 min  0.0130 max  0.8085\n",
      "Batch  139 loss: 0.15015 min  0.0128 max  0.8097\n",
      "Batch  140 loss: 0.15732 min  0.0126 max  0.8109\n",
      "Batch  141 loss: 0.15518 min  0.0125 max  0.8121\n",
      "Batch  142 loss: 0.16140 min  0.0124 max  0.8134\n",
      "Batch  143 loss: 0.14844 min  0.0123 max  0.8144\n",
      "Batch  144 loss: 0.16432 min  0.0121 max  0.8154\n",
      "Batch  145 loss: 0.15887 min  0.0120 max  0.8166\n",
      "Batch  146 loss: 0.15654 min  0.0119 max  0.8177\n",
      "Batch  147 loss: 0.15431 min  0.0117 max  0.8186\n",
      "Batch  148 loss: 0.14820 min  0.0116 max  0.8196\n",
      "Batch  149 loss: 0.14804 min  0.0116 max  0.8208\n",
      "Batch  150 loss: 0.14595 min  0.0114 max  0.8217\n",
      "Batch  151 loss: 0.13746 min  0.0113 max  0.8226\n",
      "Batch  152 loss: 0.14655 min  0.0111 max  0.8236\n",
      "Batch  153 loss: 0.14840 min  0.0110 max  0.8246\n",
      "Batch  154 loss: 0.14265 min  0.0109 max  0.8255\n",
      "Batch  155 loss: 0.13961 min  0.0108 max  0.8264\n",
      "Batch  156 loss: 0.14553 min  0.0107 max  0.8275\n",
      "Batch  157 loss: 0.14098 min  0.0106 max  0.8284\n",
      "Batch  158 loss: 0.13864 min  0.0104 max  0.8294\n",
      "Batch  159 loss: 0.14422 min  0.0103 max  0.8304\n",
      "Batch  160 loss: 0.14227 min  0.0103 max  0.8314\n",
      "Batch  161 loss: 0.13565 min  0.0101 max  0.8323\n",
      "Batch  162 loss: 0.15232 min  0.0100 max  0.8332\n",
      "Batch  163 loss: 0.14345 min  0.0099 max  0.8341\n",
      "Batch  164 loss: 0.14057 min  0.0098 max  0.8351\n",
      "Batch  165 loss: 0.13896 min  0.0097 max  0.8360\n",
      "Batch  166 loss: 0.14150 min  0.0096 max  0.8368\n",
      "Batch  167 loss: 0.13914 min  0.0095 max  0.8376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  168 loss: 0.14425 min  0.0094 max  0.8386\n",
      "Batch  169 loss: 0.13195 min  0.0093 max  0.8393\n",
      "Batch  170 loss: 0.13647 min  0.0092 max  0.8401\n",
      "Batch  171 loss: 0.13598 min  0.0091 max  0.8410\n",
      "Batch  172 loss: 0.13444 min  0.0090 max  0.8418\n",
      "Batch  173 loss: 0.12913 min  0.0089 max  0.8425\n",
      "Batch  174 loss: 0.13249 min  0.0088 max  0.8434\n",
      "Batch  175 loss: 0.13115 min  0.0087 max  0.8443\n",
      "Batch  176 loss: 0.13122 min  0.0086 max  0.8451\n",
      "Batch  177 loss: 0.12353 min  0.0085 max  0.8458\n",
      "Batch  178 loss: 0.12452 min  0.0084 max  0.8467\n",
      "Batch  179 loss: 0.13041 min  0.0084 max  0.8476\n",
      "Batch  180 loss: 0.13208 min  0.0082 max  0.8483\n",
      "Batch  181 loss: 0.13939 min  0.0081 max  0.8491\n",
      "Batch  182 loss: 0.12972 min  0.0081 max  0.8500\n",
      "Batch  183 loss: 0.13049 min  0.0080 max  0.8508\n",
      "Batch  184 loss: 0.13223 min  0.0079 max  0.8514\n",
      "Batch  185 loss: 0.12756 min  0.0079 max  0.8521\n",
      "Batch  186 loss: 0.12407 min  0.0078 max  0.8530\n",
      "Batch  187 loss: 0.12500 min  0.0077 max  0.8537\n",
      "Batch  188 loss: 0.13137 min  0.0077 max  0.8544\n",
      "Batch  189 loss: 0.12761 min  0.0076 max  0.8551\n",
      "Batch  190 loss: 0.11936 min  0.0076 max  0.8559\n",
      "Batch  191 loss: 0.12688 min  0.0075 max  0.8566\n",
      "Batch  192 loss: 0.12355 min  0.0074 max  0.8573\n",
      "Batch  193 loss: 0.12430 min  0.0074 max  0.8580\n",
      "Batch  194 loss: 0.12387 min  0.0073 max  0.8587\n",
      "Batch  195 loss: 0.12363 min  0.0072 max  0.8594\n",
      "Batch  196 loss: 0.12477 min  0.0071 max  0.8601\n",
      "Batch  197 loss: 0.12073 min  0.0071 max  0.8608\n",
      "Batch  198 loss: 0.12382 min  0.0070 max  0.8614\n",
      "Batch  199 loss: 0.11900 min  0.0069 max  0.8621\n",
      "Batch  200 loss: 0.12026 min  0.0069 max  0.8628\n",
      "Batch  201 loss: 0.12908 min  0.0068 max  0.8634\n",
      "Batch  202 loss: 0.12172 min  0.0068 max  0.8641\n",
      "Batch  203 loss: 0.12671 min  0.0067 max  0.8648\n",
      "Batch  204 loss: 0.11779 min  0.0067 max  0.8654\n",
      "Batch  205 loss: 0.11920 min  0.0066 max  0.8661\n",
      "Batch  206 loss: 0.11130 min  0.0065 max  0.8667\n",
      "Batch  207 loss: 0.11556 min  0.0065 max  0.8673\n",
      "Batch  208 loss: 0.11475 min  0.0064 max  0.8679\n",
      "Batch  209 loss: 0.11233 min  0.0064 max  0.8686\n",
      "Batch  210 loss: 0.11358 min  0.0063 max  0.8692\n",
      "Batch  211 loss: 0.11653 min  0.0062 max  0.8699\n",
      "Batch  212 loss: 0.10498 min  0.0062 max  0.8705\n",
      "Batch  213 loss: 0.12237 min  0.0061 max  0.8711\n",
      "Batch  214 loss: 0.11455 min  0.0061 max  0.8718\n",
      "Batch  215 loss: 0.10982 min  0.0060 max  0.8724\n",
      "Batch  216 loss: 0.11724 min  0.0060 max  0.8730\n",
      "Batch  217 loss: 0.11843 min  0.0059 max  0.8736\n",
      "Batch  218 loss: 0.11107 min  0.0059 max  0.8742\n",
      "Batch  219 loss: 0.11114 min  0.0058 max  0.8749\n",
      "Batch  220 loss: 0.10402 min  0.0058 max  0.8754\n",
      "Batch  221 loss: 0.11805 min  0.0057 max  0.8760\n",
      "Batch  222 loss: 0.10805 min  0.0057 max  0.8766\n",
      "Batch  223 loss: 0.10620 min  0.0056 max  0.8772\n",
      "Batch  224 loss: 0.10389 min  0.0056 max  0.8777\n",
      "Batch  225 loss: 0.11008 min  0.0055 max  0.8782\n",
      "Batch  226 loss: 0.11235 min  0.0055 max  0.8788\n",
      "Batch  227 loss: 0.11469 min  0.0054 max  0.8793\n",
      "Batch  228 loss: 0.10792 min  0.0054 max  0.8799\n",
      "Batch  229 loss: 0.10959 min  0.0053 max  0.8804\n",
      "Batch  230 loss: 0.11377 min  0.0053 max  0.8809\n",
      "Batch  231 loss: 0.10368 min  0.0052 max  0.8814\n",
      "Batch  232 loss: 0.11374 min  0.0052 max  0.8819\n",
      "Batch  233 loss: 0.11028 min  0.0051 max  0.8824\n",
      "Batch  234 loss: 0.11195 min  0.0051 max  0.8828\n",
      "Batch  235 loss: 0.11703 min  0.0051 max  0.8834\n",
      "Batch  236 loss: 0.10419 min  0.0050 max  0.8839\n",
      "Batch  237 loss: 0.11367 min  0.0050 max  0.8844\n",
      "Batch  238 loss: 0.10101 min  0.0049 max  0.8849\n",
      "Batch  239 loss: 0.10826 min  0.0049 max  0.8853\n",
      "Batch  240 loss: 0.10652 min  0.0049 max  0.8858\n",
      "Batch  241 loss: 0.10247 min  0.0048 max  0.8862\n",
      "Batch  242 loss: 0.11253 min  0.0048 max  0.8867\n",
      "Batch  243 loss: 0.10879 min  0.0048 max  0.8872\n",
      "Batch  244 loss: 0.09958 min  0.0047 max  0.8876\n",
      "Batch  245 loss: 0.10239 min  0.0047 max  0.8881\n",
      "Batch  246 loss: 0.10198 min  0.0046 max  0.8885\n",
      "Batch  247 loss: 0.10273 min  0.0046 max  0.8890\n",
      "Batch  248 loss: 0.11000 min  0.0046 max  0.8894\n",
      "Batch  249 loss: 0.09908 min  0.0045 max  0.8898\n",
      "Batch  250 loss: 0.11050 min  0.0045 max  0.8903\n",
      "Batch  251 loss: 0.11144 min  0.0044 max  0.8906\n",
      "Batch  252 loss: 0.09823 min  0.0044 max  0.8911\n",
      "Batch  253 loss: 0.11156 min  0.0044 max  0.8916\n",
      "Batch  254 loss: 0.10180 min  0.0043 max  0.8919\n",
      "Batch  255 loss: 0.10757 min  0.0043 max  0.8923\n",
      "Batch  256 loss: 0.09641 min  0.0043 max  0.8928\n",
      "Batch  257 loss: 0.10319 min  0.0042 max  0.8931\n",
      "Batch  258 loss: 0.10440 min  0.0042 max  0.8935\n",
      "Batch  259 loss: 0.10322 min  0.0042 max  0.8939\n",
      "Batch  260 loss: 0.10053 min  0.0041 max  0.8943\n",
      "Batch  261 loss: 0.10616 min  0.0041 max  0.8947\n",
      "Batch  262 loss: 0.10439 min  0.0041 max  0.8951\n",
      "Batch  263 loss: 0.10461 min  0.0041 max  0.8954\n",
      "Batch  264 loss: 0.09858 min  0.0040 max  0.8958\n",
      "Batch  265 loss: 0.09925 min  0.0040 max  0.8962\n",
      "Batch  266 loss: 0.10229 min  0.0040 max  0.8966\n",
      "Batch  267 loss: 0.10149 min  0.0039 max  0.8970\n",
      "Batch  268 loss: 0.10024 min  0.0039 max  0.8973\n",
      "Batch  269 loss: 0.10473 min  0.0039 max  0.8978\n",
      "Batch  270 loss: 0.09634 min  0.0039 max  0.8981\n",
      "Batch  271 loss: 0.10573 min  0.0038 max  0.8984\n",
      "Batch  272 loss: 0.09785 min  0.0038 max  0.8988\n",
      "Batch  273 loss: 0.09593 min  0.0038 max  0.8993\n",
      "Batch  274 loss: 0.10046 min  0.0038 max  0.8995\n",
      "Batch  275 loss: 0.10954 min  0.0037 max  0.8999\n",
      "Batch  276 loss: 0.09553 min  0.0037 max  0.9003\n",
      "Batch  277 loss: 0.10210 min  0.0037 max  0.9006\n",
      "Batch  278 loss: 0.10569 min  0.0036 max  0.9009\n",
      "Batch  279 loss: 0.10025 min  0.0036 max  0.9013\n",
      "Batch  280 loss: 0.10837 min  0.0036 max  0.9017\n",
      "Batch  281 loss: 0.09831 min  0.0036 max  0.9020\n",
      "Batch  282 loss: 0.09952 min  0.0036 max  0.9023\n",
      "Batch  283 loss: 0.09562 min  0.0036 max  0.9026\n",
      "Batch  284 loss: 0.10417 min  0.0036 max  0.9030\n",
      "Batch  285 loss: 0.09684 min  0.0035 max  0.9033\n",
      "Batch  286 loss: 0.10229 min  0.0035 max  0.9035\n",
      "Batch  287 loss: 0.10977 min  0.0035 max  0.9038\n",
      "Batch  288 loss: 0.09686 min  0.0035 max  0.9042\n",
      "Batch  289 loss: 0.11192 min  0.0035 max  0.9045\n",
      "Batch  290 loss: 0.10677 min  0.0034 max  0.9048\n",
      "Batch  291 loss: 0.09633 min  0.0034 max  0.9051\n",
      "Batch  292 loss: 0.10320 min  0.0034 max  0.9054\n",
      "Batch  293 loss: 0.09599 min  0.0034 max  0.9057\n",
      "Batch  294 loss: 0.09676 min  0.0034 max  0.9060\n",
      "Batch  295 loss: 0.10073 min  0.0034 max  0.9064\n",
      "Batch  296 loss: 0.09683 min  0.0033 max  0.9067\n",
      "Batch  297 loss: 0.09421 min  0.0033 max  0.9069\n",
      "Batch  298 loss: 0.10057 min  0.0033 max  0.9072\n",
      "Batch  299 loss: 0.10072 min  0.0033 max  0.9076\n",
      "Batch  300 loss: 0.09768 min  0.0033 max  0.9078\n",
      "Batch  301 loss: 0.09394 min  0.0032 max  0.9081\n",
      "Batch  302 loss: 0.09830 min  0.0032 max  0.9085\n",
      "Batch  303 loss: 0.09744 min  0.0032 max  0.9088\n",
      "Batch  304 loss: 0.09548 min  0.0032 max  0.9090\n",
      "Batch  305 loss: 0.09602 min  0.0032 max  0.9093\n",
      "Batch  306 loss: 0.09238 min  0.0032 max  0.9097\n",
      "Batch  307 loss: 0.09328 min  0.0031 max  0.9099\n",
      "Batch  308 loss: 0.10342 min  0.0031 max  0.9102\n",
      "Batch  309 loss: 0.09904 min  0.0031 max  0.9105\n",
      "Batch  310 loss: 0.09678 min  0.0031 max  0.9108\n",
      "Batch  311 loss: 0.09641 min  0.0031 max  0.9111\n",
      "Batch  312 loss: 0.09177 min  0.0030 max  0.9113\n",
      "Batch  313 loss: 0.09793 min  0.0030 max  0.9116\n",
      "Batch  314 loss: 0.09407 min  0.0030 max  0.9119\n",
      "Batch  315 loss: 0.09673 min  0.0030 max  0.9122\n",
      "Batch  316 loss: 0.10615 min  0.0030 max  0.9124\n",
      "Batch  317 loss: 0.09238 min  0.0029 max  0.9127\n",
      "Batch  318 loss: 0.10323 min  0.0029 max  0.9130\n",
      "Batch  319 loss: 0.09646 min  0.0029 max  0.9133\n",
      "Batch  320 loss: 0.09388 min  0.0029 max  0.9135\n",
      "Batch  321 loss: 0.09062 min  0.0029 max  0.9137\n",
      "Batch  322 loss: 0.09532 min  0.0029 max  0.9141\n",
      "Batch  323 loss: 0.08565 min  0.0029 max  0.9143\n",
      "Batch  324 loss: 0.09092 min  0.0028 max  0.9145\n",
      "Batch  325 loss: 0.09708 min  0.0028 max  0.9148\n",
      "Batch  326 loss: 0.09547 min  0.0028 max  0.9151\n",
      "Batch  327 loss: 0.09350 min  0.0028 max  0.9153\n",
      "Batch  328 loss: 0.09078 min  0.0028 max  0.9156\n",
      "Batch  329 loss: 0.09094 min  0.0028 max  0.9158\n",
      "Batch  330 loss: 0.09379 min  0.0028 max  0.9161\n",
      "Batch  331 loss: 0.09026 min  0.0027 max  0.9163\n",
      "Batch  332 loss: 0.08759 min  0.0027 max  0.9166\n",
      "Batch  333 loss: 0.08574 min  0.0027 max  0.9168\n",
      "Batch  334 loss: 0.08646 min  0.0027 max  0.9171\n",
      "Batch  335 loss: 0.09148 min  0.0027 max  0.9173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  336 loss: 0.09219 min  0.0027 max  0.9176\n",
      "Batch  337 loss: 0.09357 min  0.0026 max  0.9179\n",
      "Batch  338 loss: 0.08779 min  0.0026 max  0.9181\n",
      "Batch  339 loss: 0.08823 min  0.0026 max  0.9183\n",
      "Batch  340 loss: 0.08873 min  0.0026 max  0.9186\n",
      "Batch  341 loss: 0.09537 min  0.0026 max  0.9189\n",
      "Batch  342 loss: 0.08772 min  0.0026 max  0.9191\n",
      "Batch  343 loss: 0.08509 min  0.0025 max  0.9193\n",
      "Batch  344 loss: 0.09290 min  0.0025 max  0.9196\n",
      "Batch  345 loss: 0.09852 min  0.0025 max  0.9198\n",
      "Batch  346 loss: 0.09797 min  0.0025 max  0.9200\n",
      "Batch  347 loss: 0.08799 min  0.0025 max  0.9203\n",
      "Batch  348 loss: 0.09255 min  0.0025 max  0.9205\n",
      "Batch  349 loss: 0.09493 min  0.0025 max  0.9207\n",
      "Batch  350 loss: 0.08969 min  0.0025 max  0.9209\n",
      "Batch  351 loss: 0.09055 min  0.0025 max  0.9212\n",
      "Batch  352 loss: 0.09316 min  0.0024 max  0.9214\n",
      "Batch  353 loss: 0.08635 min  0.0024 max  0.9216\n",
      "Batch  354 loss: 0.09293 min  0.0024 max  0.9218\n",
      "Batch  355 loss: 0.08942 min  0.0024 max  0.9221\n",
      "Batch  356 loss: 0.08712 min  0.0024 max  0.9223\n",
      "Batch  357 loss: 0.08877 min  0.0024 max  0.9225\n",
      "Batch  358 loss: 0.09582 min  0.0024 max  0.9227\n",
      "Batch  359 loss: 0.09347 min  0.0024 max  0.9229\n",
      "Batch  360 loss: 0.08488 min  0.0023 max  0.9231\n",
      "Batch  361 loss: 0.09074 min  0.0023 max  0.9233\n",
      "Batch  362 loss: 0.08678 min  0.0023 max  0.9235\n",
      "Batch  363 loss: 0.08992 min  0.0023 max  0.9237\n",
      "Batch  364 loss: 0.09356 min  0.0023 max  0.9239\n",
      "Batch  365 loss: 0.08227 min  0.0023 max  0.9241\n",
      "Batch  366 loss: 0.08270 min  0.0022 max  0.9243\n",
      "Batch  367 loss: 0.08921 min  0.0022 max  0.9245\n",
      "Batch  368 loss: 0.07985 min  0.0022 max  0.9247\n",
      "Batch  369 loss: 0.08554 min  0.0022 max  0.9249\n",
      "Batch  370 loss: 0.09233 min  0.0022 max  0.9251\n",
      "Batch  371 loss: 0.08019 min  0.0022 max  0.9253\n",
      "Batch  372 loss: 0.08382 min  0.0022 max  0.9255\n",
      "Batch  373 loss: 0.08298 min  0.0022 max  0.9257\n",
      "Batch  374 loss: 0.08091 min  0.0021 max  0.9259\n",
      "Batch  375 loss: 0.08355 min  0.0021 max  0.9261\n",
      "Batch  376 loss: 0.09373 min  0.0021 max  0.9263\n",
      "Batch  377 loss: 0.08694 min  0.0021 max  0.9265\n",
      "Batch  378 loss: 0.08845 min  0.0021 max  0.9268\n",
      "Batch  379 loss: 0.09014 min  0.0021 max  0.9270\n",
      "Batch  380 loss: 0.08754 min  0.0021 max  0.9271\n",
      "Batch  381 loss: 0.10056 min  0.0021 max  0.9273\n",
      "Batch  382 loss: 0.08369 min  0.0020 max  0.9275\n",
      "Batch  383 loss: 0.09108 min  0.0020 max  0.9277\n",
      "Batch  384 loss: 0.08733 min  0.0020 max  0.9279\n",
      "Batch  385 loss: 0.09082 min  0.0020 max  0.9281\n",
      "Batch  386 loss: 0.09513 min  0.0020 max  0.9282\n",
      "Batch  387 loss: 0.09007 min  0.0020 max  0.9284\n",
      "Batch  388 loss: 0.08713 min  0.0020 max  0.9286\n",
      "Batch  389 loss: 0.09107 min  0.0020 max  0.9287\n",
      "Batch  390 loss: 0.08791 min  0.0020 max  0.9289\n",
      "Batch  391 loss: 0.09101 min  0.0020 max  0.9291\n",
      "Batch  392 loss: 0.08305 min  0.0020 max  0.9293\n",
      "Batch  393 loss: 0.08281 min  0.0020 max  0.9294\n",
      "Batch  394 loss: 0.09159 min  0.0020 max  0.9296\n",
      "Batch  395 loss: 0.08370 min  0.0019 max  0.9298\n",
      "Batch  396 loss: 0.08916 min  0.0019 max  0.9299\n",
      "Batch  397 loss: 0.09456 min  0.0019 max  0.9301\n",
      "Batch  398 loss: 0.08750 min  0.0019 max  0.9302\n",
      "Batch  399 loss: 0.08046 min  0.0019 max  0.9304\n",
      "Batch  400 loss: 0.08811 min  0.0019 max  0.9306\n",
      "Batch  401 loss: 0.08823 min  0.0019 max  0.9308\n",
      "Batch  402 loss: 0.08848 min  0.0019 max  0.9309\n",
      "Batch  403 loss: 0.07573 min  0.0019 max  0.9311\n",
      "Batch  404 loss: 0.08410 min  0.0019 max  0.9312\n",
      "Batch  405 loss: 0.07916 min  0.0019 max  0.9314\n",
      "Batch  406 loss: 0.08217 min  0.0018 max  0.9316\n",
      "Batch  407 loss: 0.08242 min  0.0018 max  0.9317\n",
      "Batch  408 loss: 0.08265 min  0.0018 max  0.9319\n",
      "Batch  409 loss: 0.08628 min  0.0018 max  0.9321\n",
      "Batch  410 loss: 0.08502 min  0.0018 max  0.9323\n",
      "Batch  411 loss: 0.08600 min  0.0018 max  0.9324\n",
      "Batch  412 loss: 0.08261 min  0.0018 max  0.9326\n",
      "Batch  413 loss: 0.08462 min  0.0018 max  0.9328\n",
      "Batch  414 loss: 0.08275 min  0.0018 max  0.9329\n",
      "Batch  415 loss: 0.08079 min  0.0018 max  0.9331\n",
      "Batch  416 loss: 0.08167 min  0.0017 max  0.9333\n",
      "Batch  417 loss: 0.08345 min  0.0017 max  0.9334\n",
      "Batch  418 loss: 0.08042 min  0.0017 max  0.9335\n",
      "Batch  419 loss: 0.08283 min  0.0017 max  0.9337\n",
      "Batch  420 loss: 0.08408 min  0.0017 max  0.9339\n",
      "Batch  421 loss: 0.07680 min  0.0017 max  0.9340\n",
      "Batch  422 loss: 0.07924 min  0.0017 max  0.9342\n",
      "Batch  423 loss: 0.08745 min  0.0017 max  0.9343\n",
      "Batch  424 loss: 0.08239 min  0.0017 max  0.9345\n",
      "Batch  425 loss: 0.07875 min  0.0017 max  0.9346\n",
      "Batch  426 loss: 0.08427 min  0.0017 max  0.9348\n",
      "Batch  427 loss: 0.08632 min  0.0016 max  0.9349\n",
      "Batch  428 loss: 0.07631 min  0.0016 max  0.9351\n",
      "Batch  429 loss: 0.08721 min  0.0016 max  0.9352\n",
      "Batch  430 loss: 0.08502 min  0.0016 max  0.9353\n",
      "Batch  431 loss: 0.08097 min  0.0016 max  0.9355\n",
      "Batch  432 loss: 0.09003 min  0.0016 max  0.9357\n",
      "Batch  433 loss: 0.08392 min  0.0016 max  0.9358\n",
      "Batch  434 loss: 0.08247 min  0.0016 max  0.9359\n",
      "Batch  435 loss: 0.08279 min  0.0016 max  0.9360\n",
      "Batch  436 loss: 0.07909 min  0.0016 max  0.9362\n",
      "Batch  437 loss: 0.07999 min  0.0016 max  0.9363\n",
      "Batch  438 loss: 0.07592 min  0.0016 max  0.9365\n",
      "Batch  439 loss: 0.08392 min  0.0016 max  0.9366\n",
      "Batch  440 loss: 0.07895 min  0.0015 max  0.9368\n",
      "Batch  441 loss: 0.08451 min  0.0015 max  0.9369\n",
      "Batch  442 loss: 0.07581 min  0.0015 max  0.9371\n",
      "Batch  443 loss: 0.07676 min  0.0015 max  0.9372\n",
      "Batch  444 loss: 0.08102 min  0.0015 max  0.9373\n",
      "Batch  445 loss: 0.07965 min  0.0015 max  0.9375\n",
      "Batch  446 loss: 0.07813 min  0.0015 max  0.9376\n",
      "Batch  447 loss: 0.07876 min  0.0015 max  0.9377\n",
      "Batch  448 loss: 0.07609 min  0.0015 max  0.9379\n",
      "Batch  449 loss: 0.07463 min  0.0015 max  0.9380\n",
      "Batch  450 loss: 0.07557 min  0.0015 max  0.9382\n",
      "Batch  451 loss: 0.07976 min  0.0015 max  0.9383\n",
      "Batch  452 loss: 0.08219 min  0.0015 max  0.9385\n",
      "Batch  453 loss: 0.07706 min  0.0015 max  0.9386\n",
      "Batch  454 loss: 0.07881 min  0.0015 max  0.9387\n",
      "Batch  455 loss: 0.08031 min  0.0014 max  0.9388\n",
      "Batch  456 loss: 0.08209 min  0.0014 max  0.9390\n",
      "Batch  457 loss: 0.08410 min  0.0014 max  0.9391\n",
      "Batch  458 loss: 0.07988 min  0.0014 max  0.9392\n",
      "Batch  459 loss: 0.07467 min  0.0014 max  0.9394\n",
      "Batch  460 loss: 0.07423 min  0.0014 max  0.9395\n",
      "Batch  461 loss: 0.08301 min  0.0014 max  0.9396\n",
      "Batch  462 loss: 0.07782 min  0.0014 max  0.9398\n",
      "Batch  463 loss: 0.07915 min  0.0014 max  0.9399\n",
      "Batch  464 loss: 0.08024 min  0.0014 max  0.9400\n",
      "Batch  465 loss: 0.07627 min  0.0014 max  0.9401\n",
      "Batch  466 loss: 0.08351 min  0.0014 max  0.9403\n",
      "Batch  467 loss: 0.08459 min  0.0014 max  0.9404\n",
      "Batch  468 loss: 0.08394 min  0.0014 max  0.9404\n",
      "Batch  469 loss: 0.07323 min  0.0014 max  0.9406\n",
      "Batch  470 loss: 0.08168 min  0.0014 max  0.9408\n",
      "Batch  471 loss: 0.08171 min  0.0013 max  0.9409\n",
      "Batch  472 loss: 0.07965 min  0.0013 max  0.9409\n",
      "Batch  473 loss: 0.07668 min  0.0013 max  0.9411\n",
      "Batch  474 loss: 0.08849 min  0.0013 max  0.9412\n",
      "Batch  475 loss: 0.07605 min  0.0013 max  0.9413\n",
      "Batch  476 loss: 0.08511 min  0.0013 max  0.9414\n",
      "Batch  477 loss: 0.08171 min  0.0013 max  0.9415\n",
      "Batch  478 loss: 0.08150 min  0.0013 max  0.9417\n",
      "Batch  479 loss: 0.08175 min  0.0013 max  0.9418\n",
      "Batch  480 loss: 0.08895 min  0.0013 max  0.9418\n",
      "Batch  481 loss: 0.08024 min  0.0013 max  0.9420\n",
      "Batch  482 loss: 0.08260 min  0.0013 max  0.9421\n",
      "Batch  483 loss: 0.07872 min  0.0013 max  0.9424\n",
      "Batch  484 loss: 0.08533 min  0.0013 max  0.9423\n",
      "Batch  485 loss: 0.08179 min  0.0013 max  0.9424\n",
      "Batch  486 loss: 0.08188 min  0.0013 max  0.9425\n",
      "Batch  487 loss: 0.08846 min  0.0013 max  0.9426\n",
      "Batch  488 loss: 0.08082 min  0.0013 max  0.9427\n",
      "Batch  489 loss: 0.08274 min  0.0013 max  0.9428\n",
      "Batch  490 loss: 0.08873 min  0.0013 max  0.9429\n",
      "Batch  491 loss: 0.08237 min  0.0013 max  0.9430\n",
      "Batch  492 loss: 0.07902 min  0.0013 max  0.9431\n",
      "Batch  493 loss: 0.07951 min  0.0013 max  0.9432\n",
      "Batch  494 loss: 0.08339 min  0.0012 max  0.9433\n",
      "Batch  495 loss: 0.08310 min  0.0012 max  0.9434\n",
      "Batch  496 loss: 0.08323 min  0.0012 max  0.9435\n",
      "Batch  497 loss: 0.07097 min  0.0012 max  0.9436\n",
      "Batch  498 loss: 0.08526 min  0.0012 max  0.9437\n",
      "Batch  499 loss: 0.08189 min  0.0012 max  0.9438\n",
      "Batch  500 loss: 0.07802 min  0.0012 max  0.9439\n",
      "Batch  501 loss: 0.08507 min  0.0012 max  0.9440\n",
      "Batch  502 loss: 0.08661 min  0.0012 max  0.9441\n",
      "Batch  503 loss: 0.08004 min  0.0012 max  0.9441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  504 loss: 0.07398 min  0.0012 max  0.9443\n",
      "Batch  505 loss: 0.09559 min  0.0012 max  0.9444\n",
      "Batch  506 loss: 0.08476 min  0.0012 max  0.9444\n",
      "Batch  507 loss: 0.07768 min  0.0012 max  0.9445\n",
      "Batch  508 loss: 0.08445 min  0.0012 max  0.9446\n",
      "Batch  509 loss: 0.08550 min  0.0012 max  0.9447\n",
      "Batch  510 loss: 0.07274 min  0.0012 max  0.9448\n",
      "Batch  511 loss: 0.09245 min  0.0012 max  0.9449\n",
      "Batch  512 loss: 0.08987 min  0.0012 max  0.9450\n",
      "Batch  513 loss: 0.08195 min  0.0012 max  0.9451\n",
      "Batch  514 loss: 0.08359 min  0.0012 max  0.9452\n",
      "Batch  515 loss: 0.08231 min  0.0012 max  0.9452\n",
      "Batch  516 loss: 0.08101 min  0.0012 max  0.9453\n",
      "Batch  517 loss: 0.07956 min  0.0012 max  0.9454\n",
      "Batch  518 loss: 0.07969 min  0.0012 max  0.9455\n",
      "Batch  519 loss: 0.07884 min  0.0011 max  0.9456\n",
      "Batch  520 loss: 0.07518 min  0.0011 max  0.9456\n",
      "Batch  521 loss: 0.07078 min  0.0011 max  0.9457\n",
      "Batch  522 loss: 0.07827 min  0.0011 max  0.9458\n",
      "Batch  523 loss: 0.08643 min  0.0011 max  0.9459\n",
      "Batch  524 loss: 0.08669 min  0.0011 max  0.9460\n",
      "Batch  525 loss: 0.07355 min  0.0011 max  0.9461\n",
      "Batch  526 loss: 0.08049 min  0.0011 max  0.9462\n",
      "Batch  527 loss: 0.08393 min  0.0011 max  0.9463\n",
      "Batch  528 loss: 0.07654 min  0.0011 max  0.9464\n",
      "Batch  529 loss: 0.07748 min  0.0011 max  0.9465\n",
      "Batch  530 loss: 0.07788 min  0.0011 max  0.9466\n",
      "Batch  531 loss: 0.08308 min  0.0011 max  0.9467\n",
      "Batch  532 loss: 0.07977 min  0.0011 max  0.9468\n",
      "Batch  533 loss: 0.07640 min  0.0011 max  0.9469\n",
      "Batch  534 loss: 0.08039 min  0.0011 max  0.9470\n",
      "Batch  535 loss: 0.07765 min  0.0011 max  0.9471\n",
      "Batch  536 loss: 0.07901 min  0.0011 max  0.9472\n",
      "Batch  537 loss: 0.07585 min  0.0011 max  0.9473\n",
      "Batch  538 loss: 0.07606 min  0.0011 max  0.9474\n",
      "Batch  539 loss: 0.07863 min  0.0011 max  0.9475\n",
      "Batch  540 loss: 0.07850 min  0.0011 max  0.9476\n",
      "Batch  541 loss: 0.07890 min  0.0011 max  0.9476\n",
      "Batch  542 loss: 0.07974 min  0.0011 max  0.9477\n",
      "Batch  543 loss: 0.09039 min  0.0011 max  0.9478\n",
      "Batch  544 loss: 0.07040 min  0.0011 max  0.9479\n",
      "Batch  545 loss: 0.08508 min  0.0011 max  0.9480\n",
      "Batch  546 loss: 0.07870 min  0.0011 max  0.9481\n",
      "Batch  547 loss: 0.07399 min  0.0011 max  0.9482\n",
      "Batch  548 loss: 0.07670 min  0.0010 max  0.9483\n",
      "Batch  549 loss: 0.07920 min  0.0010 max  0.9484\n",
      "Batch  550 loss: 0.07549 min  0.0010 max  0.9485\n",
      "Batch  551 loss: 0.07343 min  0.0010 max  0.9486\n",
      "Batch  552 loss: 0.07718 min  0.0010 max  0.9487\n",
      "Batch  553 loss: 0.07559 min  0.0010 max  0.9487\n",
      "Batch  554 loss: 0.07748 min  0.0010 max  0.9488\n",
      "Batch  555 loss: 0.08182 min  0.0010 max  0.9489\n",
      "Batch  556 loss: 0.07426 min  0.0010 max  0.9490\n",
      "Batch  557 loss: 0.07708 min  0.0010 max  0.9491\n",
      "Batch  558 loss: 0.07764 min  0.0010 max  0.9491\n",
      "Batch  559 loss: 0.08098 min  0.0010 max  0.9492\n",
      "Batch  560 loss: 0.07297 min  0.0010 max  0.9493\n",
      "Batch  561 loss: 0.06999 min  0.0010 max  0.9494\n",
      "Batch  562 loss: 0.07180 min  0.0010 max  0.9495\n",
      "Batch  563 loss: 0.07216 min  0.0010 max  0.9496\n",
      "Batch  564 loss: 0.07739 min  0.0010 max  0.9497\n",
      "Batch  565 loss: 0.07130 min  0.0010 max  0.9497\n",
      "Batch  566 loss: 0.07506 min  0.0010 max  0.9498\n",
      "Batch  567 loss: 0.07181 min  0.0010 max  0.9499\n",
      "Batch  568 loss: 0.07523 min  0.0010 max  0.9500\n",
      "Batch  569 loss: 0.07150 min  0.0010 max  0.9501\n",
      "Batch  570 loss: 0.07900 min  0.0010 max  0.9502\n",
      "Batch  571 loss: 0.08141 min  0.0010 max  0.9503\n",
      "Batch  572 loss: 0.07784 min  0.0009 max  0.9504\n",
      "Batch  573 loss: 0.08316 min  0.0009 max  0.9504\n",
      "Batch  574 loss: 0.08381 min  0.0009 max  0.9505\n",
      "Batch  575 loss: 0.08466 min  0.0009 max  0.9506\n",
      "Batch  576 loss: 0.07750 min  0.0009 max  0.9507\n",
      "Batch  577 loss: 0.07563 min  0.0009 max  0.9507\n",
      "Batch  578 loss: 0.07294 min  0.0009 max  0.9508\n",
      "Batch  579 loss: 0.07534 min  0.0009 max  0.9509\n",
      "Batch  580 loss: 0.07907 min  0.0009 max  0.9510\n",
      "Batch  581 loss: 0.07652 min  0.0009 max  0.9510\n",
      "Batch  582 loss: 0.08209 min  0.0009 max  0.9511\n",
      "Batch  583 loss: 0.07657 min  0.0009 max  0.9512\n",
      "Batch  584 loss: 0.07413 min  0.0009 max  0.9512\n",
      "Batch  585 loss: 0.07419 min  0.0009 max  0.9513\n",
      "Batch  586 loss: 0.07719 min  0.0009 max  0.9513\n",
      "Batch  587 loss: 0.07291 min  0.0009 max  0.9514\n",
      "Batch  588 loss: 0.07442 min  0.0009 max  0.9515\n",
      "Batch  589 loss: 0.07899 min  0.0009 max  0.9516\n",
      "Batch  590 loss: 0.07503 min  0.0009 max  0.9516\n",
      "Batch  591 loss: 0.07564 min  0.0009 max  0.9517\n",
      "Batch  592 loss: 0.07537 min  0.0009 max  0.9518\n",
      "Batch  593 loss: 0.07245 min  0.0009 max  0.9519\n",
      "Batch  594 loss: 0.07704 min  0.0009 max  0.9520\n",
      "Batch  595 loss: 0.07381 min  0.0009 max  0.9520\n",
      "Batch  596 loss: 0.08053 min  0.0009 max  0.9521\n",
      "Batch  597 loss: 0.07110 min  0.0009 max  0.9522\n",
      "Batch  598 loss: 0.07448 min  0.0009 max  0.9522\n",
      "Batch  599 loss: 0.07435 min  0.0009 max  0.9523\n",
      "Batch  600 loss: 0.07258 min  0.0009 max  0.9524\n",
      "Batch  601 loss: 0.07053 min  0.0009 max  0.9525\n",
      "Batch  602 loss: 0.07514 min  0.0009 max  0.9525\n",
      "Batch  603 loss: 0.07657 min  0.0009 max  0.9526\n",
      "Batch  604 loss: 0.07305 min  0.0009 max  0.9527\n",
      "Batch  605 loss: 0.07817 min  0.0009 max  0.9528\n",
      "Batch  606 loss: 0.07313 min  0.0009 max  0.9528\n",
      "Batch  607 loss: 0.07600 min  0.0008 max  0.9529\n",
      "Batch  608 loss: 0.07553 min  0.0008 max  0.9530\n",
      "Batch  609 loss: 0.07309 min  0.0008 max  0.9530\n",
      "Batch  610 loss: 0.08265 min  0.0008 max  0.9531\n",
      "Batch  611 loss: 0.07185 min  0.0008 max  0.9532\n",
      "Batch  612 loss: 0.08170 min  0.0008 max  0.9533\n",
      "Batch  613 loss: 0.08011 min  0.0008 max  0.9533\n",
      "Batch  614 loss: 0.07128 min  0.0008 max  0.9534\n",
      "Batch  615 loss: 0.07771 min  0.0008 max  0.9535\n",
      "Batch  616 loss: 0.07590 min  0.0008 max  0.9536\n",
      "Batch  617 loss: 0.07782 min  0.0008 max  0.9536\n",
      "Batch  618 loss: 0.07681 min  0.0008 max  0.9536\n",
      "Batch  619 loss: 0.07570 min  0.0008 max  0.9537\n",
      "Batch  620 loss: 0.07891 min  0.0008 max  0.9538\n",
      "Batch  621 loss: 0.07319 min  0.0008 max  0.9538\n",
      "Batch  622 loss: 0.07020 min  0.0008 max  0.9539\n",
      "Batch  623 loss: 0.07510 min  0.0008 max  0.9539\n",
      "Batch  624 loss: 0.07488 min  0.0008 max  0.9540\n",
      "Batch  625 loss: 0.07387 min  0.0008 max  0.9541\n",
      "Batch  626 loss: 0.07360 min  0.0008 max  0.9541\n",
      "Batch  627 loss: 0.07731 min  0.0008 max  0.9542\n",
      "Batch  628 loss: 0.07970 min  0.0008 max  0.9543\n",
      "Batch  629 loss: 0.06417 min  0.0008 max  0.9543\n",
      "Batch  630 loss: 0.07372 min  0.0008 max  0.9544\n",
      "Batch  631 loss: 0.07770 min  0.0008 max  0.9545\n",
      "Batch  632 loss: 0.07635 min  0.0008 max  0.9545\n",
      "Batch  633 loss: 0.06942 min  0.0008 max  0.9546\n",
      "Batch  634 loss: 0.07191 min  0.0008 max  0.9547\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3775fdd3f6f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# Calc all gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Step optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/main/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/main/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "use_cuda = False\n",
    "\n",
    "# Ball params\n",
    "input_size = (10,10)\n",
    "# Radius uniform distribution\n",
    "radius = (3,3)\n",
    "\n",
    "# Network params\n",
    "input_dim = 1\n",
    "hidden_dim = [16,8,8]\n",
    "num_layers = len(hidden_dim)\n",
    "kernel_size = (5,5)\n",
    "\n",
    "# Meta params\n",
    "learning_rate = .01\n",
    "n_batches = 1000\n",
    "# TODO: Implement getting multiple batches of Ball() sequences\n",
    "batch_size = 100\n",
    "# These sum to sequence length\n",
    "inputs_seq_len = 5\n",
    "outputs_seq_len = 5\n",
    "\n",
    "# Velocity relates to kernel size\n",
    "b = Ball(shape=input_size, radius=radius, velocity=2, gravity=0, bounce=True)\n",
    "\n",
    "encoder = ConvLSTM(input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=True, bias=True, return_all_layers=True, use_cuda=use_cuda)\n",
    "decoder = ConvLSTM(input_size, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=True, bias=True, return_all_layers=True, use_cuda=use_cuda)\n",
    "# Default weights should be ok\n",
    "decoder_output_conv = torch.nn.Conv2d(in_channels=hidden_dim[-1], out_channels=1, kernel_size=(1,1),\n",
    "                                     padding=0, bias=True)\n",
    "\n",
    "optim = torch.optim.Adam(itertools.chain(\n",
    "    encoder.parameters(),\n",
    "    decoder.parameters(),\n",
    "    decoder_output_conv.parameters()), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i_b in range(n_batches):\n",
    "    # (b, t, c, h, w)\n",
    "    batch = b(batch_size=batch_size, sequence_length=inputs_seq_len + outputs_seq_len)\n",
    "\n",
    "    # Targets includes the last input\n",
    "    inputs, targets = batch[:,:inputs_seq_len], batch[:,-outputs_seq_len:]\n",
    "\n",
    "    inputs_var = Variable(torch.from_numpy(inputs), requires_grad=True)\n",
    "    targets_var = Variable(torch.from_numpy(targets))\n",
    "    \n",
    "    if use_cuda:\n",
    "        inputs_var = inputs_var.cuda()\n",
    "        targets_var = targets_var.cuda()\n",
    "        \n",
    "    # TODO: BREAK OUT INTO INFERENCE FUNCTION FROM HERE (args inputs_var, targets_var)\n",
    "\n",
    "    # Compute encoded state\n",
    "    # We don't care about outputs other than the last one\n",
    "    enc_layer_output_list, enc_last_state_list = encoder.forward(inputs_var)\n",
    "\n",
    "    # Compute time series using encoded state\n",
    "    # No conditioning on own outputs\n",
    "    # TODO: Implement forward pass with input=0, e.g. generate zero matrices\n",
    "    dummy_inputs = Variable(torch.zeros_like(targets_var.data))\n",
    "    if use_cuda:\n",
    "        dummy_target_inputs = dummy_target_inputs.cuda()\n",
    "    # Pass last state\n",
    "    dec_layer_output_list, dec_last_state_list = decoder.forward(dummy_inputs, hidden_state=enc_last_state_list)\n",
    "    \n",
    "    # Get highest layer h\n",
    "    last_layer_h = dec_layer_output_list[-1]\n",
    "    # Map to output using 1x1 convolution\n",
    "    # preds is ordered list of predictions\n",
    "    # TODO: Test if convolution from all h,c at the same time works better\n",
    "    preds = [decoder_output_conv(last_layer_h[:,timestep]) for timestep in range(targets.shape[1])]\n",
    "    # Run through sigmoid to restrict to range [0,1], and make it possible to use cross-entropy loss\n",
    "#     preds = [torch.nn.functional.hardtanh(p)*.5+.5 for p in preds]\n",
    "    preds = [torch.sigmoid(p) for p in preds]\n",
    "    \n",
    "    # TODO: BREAK OUT INTO INFERENCE FUNCTION UNTIL HERE (return preds)\n",
    "    \n",
    "    # Calculate error\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    loss = 0\n",
    "    for i_t, p in enumerate(preds):\n",
    "        loss += loss_func(p, targets_var[:,i_t])\n",
    "    \n",
    "    # Don't forget to zero the gradient\n",
    "    optim.zero_grad()\n",
    "    # Calc all gradients\n",
    "    loss.backward()\n",
    "    # Step optimizer\n",
    "    optim.step()\n",
    "\n",
    "    print(\"Batch {:4d} loss: {:.5f} min {: 2.4f} max {: 2.4f}\".format(i_b, loss.data[0],\n",
    "                            min(arr.min().data[0] for arr in preds), max(arr.max().data[0] for arr in preds)))\n",
    "    losses.append(loss.data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest: 0.06417\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f806cbb21d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(\"Training loss per batch\")\n",
    "ax.set_ylabel('MSE loss')\n",
    "ax.plot(losses)\n",
    "ax.set_yscale('log')\n",
    "print(\"Lowest: {:.5f}\".format(min(losses)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch = 30\n",
    "\n",
    "inp = [inputs[batch,timestep,0] for timestep in range(inputs.shape[1])]\n",
    "p = [v[batch,0].data for v in preds]\n",
    "\n",
    "utils.plotting.plot_synthetic(inp+p, interval=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:main]",
   "language": "python",
   "name": "conda-env-main-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
